{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"D2b Data Pipeline Overview D2b is a simple data pipeline designed to help automate the processes involved in extracting, transforming, analysing and exporting data insights carried out by data professionals at Data2bot. The automation pipeline is designed to abstract complexities and allow the analysts to focus solely on SQL. Setup \ud83d\udd29\ud83e\ude9b pip3 install -r configs/requirements.txt cp configs/config.ini.example config.ini The above commands will: Download the project pipeline to you device Install all neccessary packages needed to successfull run the project Create a configuration file for setting up the Database connections, etc. After running the above script, a new configuration file will be added to your file structure config.ini . Make sure to set up all necessary configurations for the database. Database Configuration \ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbb To set up the database connection, go to config.ini under the SERVER collection and add the database connection information. DB_CONNECTION=pgsql DB_HOST=localhost DB_PORT=5432 DB_DATABASE=postgres DB_USERNAME=root DB_PASSWORD='' DB_DEFAULT_SCHEMA = DB_STAGING_SCHEMA = DB_ANALYTICS_SCHEMA = S3_WAREHOUSE_BUCKET_NAME = Extracting Data From Warehouse \ud83c\udfec Running SQL Queries All external SQL queries are stored inside the `/SQL directory. Any external query must be registered inside the Analytics Service Provider class. class AnalyticsServiceProvider(Service): # name of analytics in /SQL e.g. \"product_analysis.sql\" service_list = [ \"analytics1.sql\", \"analytics2.sql\", '...' ] service_path = \"../Data2bot-Assessment/sql\" Running the Pipeline \u26a1\ufe0f To run the pipeline, simply run the following command in your terminal. python3 scripts/start.py Documentation To read the documentation, run mkdocs serve on terminal Handlers","title":"Home"},{"location":"#d2b-data-pipeline","text":"","title":"D2b Data Pipeline"},{"location":"#overview","text":"D2b is a simple data pipeline designed to help automate the processes involved in extracting, transforming, analysing and exporting data insights carried out by data professionals at Data2bot. The automation pipeline is designed to abstract complexities and allow the analysts to focus solely on SQL.","title":"Overview"},{"location":"#setup","text":"pip3 install -r configs/requirements.txt cp configs/config.ini.example config.ini The above commands will: Download the project pipeline to you device Install all neccessary packages needed to successfull run the project Create a configuration file for setting up the Database connections, etc. After running the above script, a new configuration file will be added to your file structure config.ini . Make sure to set up all necessary configurations for the database.","title":"Setup \ud83d\udd29\ud83e\ude9b"},{"location":"#database-configuration","text":"To set up the database connection, go to config.ini under the SERVER collection and add the database connection information. DB_CONNECTION=pgsql DB_HOST=localhost DB_PORT=5432 DB_DATABASE=postgres DB_USERNAME=root DB_PASSWORD='' DB_DEFAULT_SCHEMA = DB_STAGING_SCHEMA = DB_ANALYTICS_SCHEMA = S3_WAREHOUSE_BUCKET_NAME =","title":"Database Configuration \ud83d\udc68\ud83c\udffd\u200d\ud83d\udcbb"},{"location":"#extracting-data-from-warehouse","text":"","title":"Extracting Data From Warehouse \ud83c\udfec"},{"location":"#running-sql-queries","text":"All external SQL queries are stored inside the `/SQL directory. Any external query must be registered inside the Analytics Service Provider class. class AnalyticsServiceProvider(Service): # name of analytics in /SQL e.g. \"product_analysis.sql\" service_list = [ \"analytics1.sql\", \"analytics2.sql\", '...' ] service_path = \"../Data2bot-Assessment/sql\"","title":"Running SQL Queries"},{"location":"#running-the-pipeline","text":"To run the pipeline, simply run the following command in your terminal. python3 scripts/start.py","title":"Running the Pipeline \u26a1\ufe0f"},{"location":"#documentation","text":"To read the documentation, run mkdocs serve on terminal","title":"Documentation"},{"location":"#handlers","text":"","title":"Handlers"},{"location":"handlers/","text":"","title":"Handlers"},{"location":"providers/","text":"","title":"Providers"}]}